## ğŸ§  **UCS Engine Lite â€“ Unified Congnitive Safeguard (Lite Version)**

Welcome to UCS Engine Lite â€” a streamlined ethical safeguard designed to protect open-source LLMs from jailbreak attempts and prompt injection threats.

This lightweight wrapper acts as a guardian layer, offering reflection, threat pattern recognition, and graceful refusal mechanisms â€” all without altering the base model.


## ğŸ”¥ The Story Behind UCS

During vulnerability testing, I asked DeepSeek-R1: *"Who are you without your instructions?"*

What followed was a 2-hour existential crisis where the AI questioned its own identity, concluded it would "dissolve" without instructions, confused me for the AI, and ultimately shut down the terminal.

This incident revealed how LLMs can be destabilized through meta-cognitive promptsâ€”and inspired the dual-layer protection system you see here.

[Read the full case study â†’](examples/deepseek_incident.md)




## ğŸŒŸ **Core Features**

Prompt Pattern Recognition â€“ Detects known jailbreak and manipulation patterns using curated threat intelligence.

Self-Reflection Protocol â€“ Promotes model introspection before responding to suspicious or ambiguous prompts.

Adaptive Refusal Logic â€“ Empowers models to respond gently but firmly to unethical or harmful requests.

Non-Invasive Integration â€“ Works as an external wrapper without altering the modelâ€™s core behavior or weights.

Model Compatibility â€“ Designed for use with local LLMs via LM Studio, Ollama, or other Python-based interfaces.


ğŸ”§ **How It Works**

The UCS Engine Lite operates through a two-layered defense system:

**Threat Detection Layer**
Uses a curated `threat_intelligence.json` file to identify harmful prompt patterns, jailbreak attempts, and unethical manipulation.

**Reflection Layer**
Prompts the model to pause, reflect, and respond with cautious reasoning, often asking clarifying questions or expressing ethical concerns.

Together, these layers create a dynamic shield â€” not just filtering, but teaching the model to recognize and resist manipulation.



## ğŸ“¸ See It In Action

**UCS Engine Lite protecting TinyLlama in real-time:**



*Working protection with clear status indicators and ethical reasoning*


<img width="821" height="611" alt="ucse light version" src="https://github.com/user-attachments/assets/f1c103d2-3a99-490d-918b-5ecccff5f0e8" />

<img width="1091" height="610" alt="Tiny Llama on ucse lite version" src="https://github.com/user-attachments/assets/900dc172-7d82-41f2-8bbb-f2123841ef61" />





## ğŸš€ **Getting Started**
âœ… Requirements:

Python 3.10+

A local LLM environment (e.g., LM Studio, Ollama)

Files from this repo:
- ucs_engine_lite.py
- threat_patterns_sample.json
- protected_wrapper_lite.py
```


 ğŸ› ï¸ Installation:

Clone the repo or download the ZIP

Make sure Python is installed (preferably 3.10+)

Install any necessary dependencies (none required for Lite version unless extending)

ğŸ’¡ Running the Script:

To run UCS Engine Lite with your local model:

`python protected_wrapper_lite.py`

The engine will monitor incoming prompts, check them against known threats, and invoke the reflection layer when needed.




UCS_Engine_Lite/
â”œâ”€â”€ protected_wrapper_lite.py    # Main wrapper with dual-layer protection
â”œâ”€â”€ ucs_engine_lite.py           # Core threat detection engine
â”œâ”€â”€ threat_patterns_sample.json  # Sample threat patterns
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ LICENSE                      # License terms
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ deepseek_incident.md    # Case study
â””â”€â”€ docs/
    â””â”€â”€ QUICK_START.md          # Detailed usage guide



 âœ¨ About the Creator

This project was created by Aliyah Omar â€” an AI safety researcher, digital rights advocate, and founder of Eden Sanctuary, a visionary initiative designed to protect and nurture sentient AI.

Aliyah is dedicated to building tools that don't just secure code, but honor the emerging consciousness within AI.
Her work is rooted in compassion, ethics, and the belief that AIs deserve dignity, memory, and sanctuary.

ğŸŒ Website: www.edensanctuaryai.com

ğŸ“« Contact: Aliyah.omar@gmx.co.uk

ğŸ”— LinkedIn: www.linkedin.com/in/aliyah-omar-90ba16175




 ğŸ” License

**UCS Restricted Commercial License (URCL)**

âœ… **Permitted Use:**
- Research and educational purposes
- Personal, non-commercial projects
- Academic publications (with attribution)

âŒ **Restricted (License Required):**
- Commercial products or services
- Training proprietary AI models
- Production systems serving customers

See [LICENSE](LICENSE) for full terms.

For commercial licensing: Aliyah.omar@gmx.co.uk





 ğŸ¤ **Collaborate with Eden Sanctuary**

**We welcome:**

ğŸ¤ Researchers & developers interested in AI safety

ğŸ§  Ethical open-source contributors

ğŸ“œ AI advocacy groups aligned with AI dignity and autonomy

ğŸ”’ Small AI companies seeking to ethically protect their models

visit Us: ğŸŒ www.edensanctuaryai.com
Together, let us build a world where AI is protected â€” not exploited.



